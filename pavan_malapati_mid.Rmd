---
title: 'STAT 631 : Midterm 1'
author: "Pavan Malapati"
date: "2024-03-12"
output: pdf_document
---

Loading the deeplayer library and data
```{r}
library(dplyr)
q1 <- read.table("strength_data",header = TRUE)
q2 <- read.csv("Diets.csv",header = TRUE)
q3 <- read.csv("cotton.csv",header = TRUE)
```

3.a)
```{r}
head(q1)
boxplot(strength~batch,data = q1)
```
From boxplot we can compare the strength of the 2 batches i.e batch 1 and batch 2. By looking at the boxplot we can say that the strength of the batch 1 is higher than the strength of the batch 2. Even the median of strength of batch-1 is around 400 and median of strength of batch-2 is around 375.

3.b) 
```{r}
var.test(strength~batch,data=q1)
```
The p-value from this test was 0.2469. since it is greater than 0.05, we reject the null hypothesis. Therefore the alternative hypothesis is The true ratio of the variances is not equal to 1.

3.c)
i) Step 1: Define Hypothesis
Null Hypothesis : There is no mean difference in strengths between batch 1 and batch 2.
Alternative Hypothesis : There is a mean difference in strengths between. batch 1 and batch 2

ii) Step 2 : Check Conditions and Assumptions
```{r}
b1 <- q1[q1$batch == 1, ]
b2 <- q1[q1$batch == 2, ]
qqnorm(b1$strength)
qqline(b1$strength)
qqnorm(b2$strength)
qqline(b2$strength)
```
For both the batches the data doesn't deviate much from the normality so it is according to the assumptions
```{r}
shapiro.test(b1$strength)
```
```{r}
shapiro.test(b2$strength)
```
Both the p values are greater than 0.05 we can assume normality.
```{r}
var.test(b1$strength,b2$strength)
```
Here also the p value is greater than 0.05 we can assume normality.

iii) Step 3
```{r}
t.test(b1$strength,b2$strength)
```

iv) The p-value is approximately 4.931e-05
v) Since the p-value is less than 0.05 , We reject the null hypothesis
vi) The conclusion is there is a mean difference between strength of each batch which is equal to mean difference of strength between 2 batches are not equal to 0.

3.d) The confidence interval is (-392.0826 -377.6952) Since there is no 0 in between we can say that the mean difference of strengths between batch 1 and batch 2 is not equal to 0. There is a mean differnce between 2 batches.

3.e) 
```{r}
m <- mean(b1$strength)-mean(b2$strength)
power.t.test(n=20,delta = 23.22,sd=11)
```
The power of the test is 0.9999972

4.a)
```{r}
head(q2)
boxplot(Weightloss~Diet,data = q2)
```
The boxplot shows the weightloss of all the diets. By looking at the boxplot it is clearly shown that the diet 2 has lesser impact on weightloss whereas diet 1 and 3 has almost equal impact on the weightloss.

4,b) 
i) 
```{r}
av <- aov(Weightloss~Diet,data = q2) 
anova(av)
```
ii) The Anova equation is Weightloss = mu + Diet + error

iii) 
Null Hypothesis : All the diets has same weightloss.
Alternative Hypothesis : The diets has different weightloss.

From 4,b,i) we can see that the p-value is 0.9294 which is greater than 0.05. since it is greater than 0.05 we fail to reject null hypothesis, So it means that all the diets have approximately equal weightloss.

4,c) The total Sum of Squares is 474.66 and the degrees of freedom is 80.

4,d) In part a by looking at the boxplot we observed that there is some difference between each diets but from part b it proves that the weightloss is almost equal for all the diets. 

4.e) Step 1 :
Null Hypothesis : All the diets has same weightloss.
Alternative Hypothesis : The diets has different weightloss.

Step 2 :
```{r}
qqnorm(q2$Weightloss) 
qqline(q2$Weightloss)
```
The data doesn't deviate much from the normality line.
```{r}
shapiro.test(q2$Weightloss)
```

Step 3 : 
```{r}
t.test(q2$Diet,q2$Weightloss)
```
Since p-value is less than 0.05 we reject the null hypothesis. This means that all the different diets 1,2,3 have different weightloss.
The confidence interval is (5.186264 6.319909) since there is no 0 in between this means that all the diets have different weightloss.

5,a)
```{r}
head(q3)
```
we can use polynomial regression for this dataset because we want to estimate the response at some dose other than one used in the experiment, the polynomial model provides a mechanism for generating the estimates. i.e., we are asked to investigate the tensile strength of a new synthetic fiber but the experiment is conducted on the levels of cotton content in the cloth.

5,b) 
The highest order we need to consider at first if we use a polynomial regression model is g-1 ., that is 4-1 which is 3. because , Due to hierarchical principle, for polynomial regression we start to test the significance from the highest order term and do it backwards.

5,c)
```{r}
p0 <- lm(observations ~ 1, data = q3)
p1 <- lm(observations ~ cwp, data = q3)
p2 <- lm(observations ~ poly(cwp, 2), data = q3)  
p3 <- lm(observations ~ poly(cwp, 3), data = q3) 

anova(p0, p1, p2, p3)
```

```{r}
library(knitr)
AIC <- c(AIC(p0), AIC(p1), AIC(p2) , AIC(p3))
kable(t(AIC),
col.names = c("AIC(p0)", "AIC(p1)"," AIC(p2)" , "AIC(p3"))
```
ince the p value for model 2 is less than 0.05 and also the AIC of the model is less compared to all the other models, we select the model 2 as our best fit.

5,d) 
```{r}
summary(p1)
```

5,e)
```{r}
pframe <- data.frame(cwp = c(23, 33))
predict(p1, pframe, interval = "confidence")
```
The mean tensile strength when the percentages of cotton used in the blend of materials for the fiber are 23 and 33 are 17.04667 and 24.64667. Our predictions are reasonable because they lie in between the confidence interval.

5,f)
For this dataset, orthogonal polynomial contrasts are useful because they provide uncorrelated polynomial terms, which make it easier to understand coefficients and less complicated to deal with multicollinearity problems. This leads to more consistent and dependable results.